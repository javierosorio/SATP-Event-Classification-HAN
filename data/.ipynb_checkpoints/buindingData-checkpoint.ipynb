{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil import parser\n",
    "import copy\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "from nltk import tokenize\n",
    "import io\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import csv\n",
    "\n",
    "# Generating data for HAN (for building classifier to predict 17 crime tags)\n",
    "\n",
    "random.seed(777777)\n",
    "\n",
    "crimes = [\"Oil Theft\",\n",
    "            \"Microtrafficking\",\n",
    "            \"Human Trafficking\",\n",
    "            \"Human Smuggling\",\n",
    "            \"Arms Trafficking\",\n",
    "            \"Homicides\",\n",
    "            \"Cyber Crime\",\n",
    "            \"Criminal Migration\",\n",
    "            \"Counterfeit\",\n",
    "            \"Contraband\",\n",
    "            \"Extortion\",\n",
    "            \"Gender and Organized Crime\",\n",
    "            \"Money Laundering\",\n",
    "            \"European Organized Crime\",\n",
    "            \"Illegal Mining\",\n",
    "            \"Eco-Trafficking\",\n",
    "            \"Kidnapping\"]\n",
    "\n",
    "crimesEncoding = {\"Oil Theft\":1,\n",
    "            \"Microtrafficking\":2,\n",
    "            \"Human Trafficking\":3,\n",
    "            \"Human Smuggling\":4,\n",
    "            \"Arms Trafficking\":5,\n",
    "            \"Homicides\":6,\n",
    "            \"Cyber Crime\":7,\n",
    "            \"Criminal Migration\":8,\n",
    "            \"Counterfeit\":9,\n",
    "            \"Contraband\":10,\n",
    "            \"Extortion\":11,\n",
    "            \"Gender and Organized Crime\":12,\n",
    "            \"Money Laundering\":13,\n",
    "            \"European Organized Crime\":14,\n",
    "            \"Illegal Mining\":15,\n",
    "            \"Eco-Trafficking\":16,\n",
    "            \"Kidnapping\":17}\n",
    "\n",
    "\n",
    "data_file = 'crime_tags.json'\n",
    "prevText = None\n",
    "\n",
    "with open(data_file) as f:\n",
    "\n",
    "    for line in f:\n",
    "        d = json.loads(line)\n",
    "\n",
    "        text = d['content']\n",
    "        tags = d['tags']\n",
    "\n",
    "        # Skip duplicated articles\n",
    "        if text[0:50] == prevText:\n",
    "            pass\n",
    "        else:\n",
    "            prevText = text[0:50] \n",
    "\n",
    "        label = None\n",
    "        labelTag = None\n",
    "        for tag in tags:\n",
    "            if tag in crimes:\n",
    "                label = crimesEncoding[tag]\n",
    "                labelTag = tag\n",
    "                break\n",
    "\n",
    "        if label != None:\n",
    "\n",
    "            rand = random.random()\n",
    "\n",
    "            if rand <= 0.6666:\n",
    "\n",
    "                with open('train.csv', mode='a') as employee_file:\n",
    "                    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    employee_writer.writerow([label, text])\n",
    "\n",
    "            else:\n",
    "                with open('test.csv', mode='a') as employee_file:\n",
    "                    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    employee_writer.writerow([label, text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil import parser\n",
    "import copy\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "from nltk import tokenize\n",
    "import io\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import csv\n",
    "\n",
    "totalTrain = 0\n",
    "totalTest = 0\n",
    "\n",
    "labelsFreq = {}\n",
    "\n",
    "\n",
    "with open('train.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        label = row[0]\n",
    "        totalTrain += 1\n",
    "        if label in labelsFreq:\n",
    "            labelsFreq[label] = labelsFreq[label] + 1 \n",
    "        else: \n",
    "            labelsFreq[label] = 1 \n",
    "        \n",
    "with open('test.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        \n",
    "        label = row[0]\n",
    "        totalTest += 1\n",
    "        if label in labelsFreq:\n",
    "            labelsFreq[label] = labelsFreq[label] + 1 \n",
    "        else: \n",
    "            labelsFreq[label] = 1 \n",
    "            \n",
    "            \n",
    "print('Total Training Sentences: ', totalTrain)\n",
    "print('Total Testing Sentences: ', totalTest)\n",
    "for k, v in labelsFreq.items():\n",
    "    print(k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
