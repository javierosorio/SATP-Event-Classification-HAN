{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a8c20c82de09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0memployee_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memployee_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_MINIMAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcrimesTextsTrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0memployee_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil import parser\n",
    "import copy\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "from nltk import tokenize\n",
    "import io\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import csv\n",
    "\n",
    "# Generating data for HAN (for building classifier to predict 17 crime tags)\n",
    "\n",
    "random.seed(777777)\n",
    "\n",
    "crimes = [\"Oil Theft\",\n",
    "            \"Microtrafficking\",\n",
    "            \"Human Trafficking\",\n",
    "            \"Human Smuggling\",\n",
    "            \"Arms Trafficking\",\n",
    "            \"Homicides\",\n",
    "            \"Cyber Crime\",\n",
    "            \"Criminal Migration\",\n",
    "            \"Counterfeit\",\n",
    "            \"Contraband\",\n",
    "            \"Extortion\",\n",
    "            \"Gender and Organized Crime\",\n",
    "            \"Money Laundering\",\n",
    "            \"European Organized Crime\",\n",
    "            \"Illegal Mining\",\n",
    "            \"Eco-Trafficking\",\n",
    "            \"Kidnapping\"]\n",
    "\n",
    "crimesEncoding = {\"Oil Theft\":1,\n",
    "            \"Microtrafficking\":2,\n",
    "            \"Human Trafficking\":3,\n",
    "            \"Human Smuggling\":4,\n",
    "            \"Arms Trafficking\":5,\n",
    "            \"Homicides\":6,\n",
    "            \"Cyber Crime\":7,\n",
    "            \"Criminal Migration\":8,\n",
    "            \"Counterfeit\":9,\n",
    "            \"Contraband\":10,\n",
    "            \"Extortion\":11,\n",
    "            \"Gender and Organized Crime\":12,\n",
    "            \"Money Laundering\":13,\n",
    "            \"European Organized Crime\":14,\n",
    "            \"Illegal Mining\":15,\n",
    "            \"Eco-Trafficking\":16,\n",
    "            \"Kidnapping\":17}\n",
    "\n",
    "\n",
    "\n",
    "crimesTextsTrain = {crime: \"\" for crime in crimes}\n",
    "crimesTextsTest = {crime: \"\" for crime in crimes}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_file = 'crime_tags.json'\n",
    "prevText = None\n",
    "\n",
    "with open(data_file) as f:\n",
    "\n",
    "    for line in f:\n",
    "        d = json.loads(line)\n",
    "\n",
    "        text = d['content']\n",
    "        tags = d['tags']\n",
    "\n",
    "        # Skip duplicated articles\n",
    "        if text[0:50] == prevText:\n",
    "            pass\n",
    "        else:\n",
    "            prevText = text[0:50] \n",
    "\n",
    "        label = None\n",
    "        labelTag = None\n",
    "        for tag in tags:\n",
    "            if tag in crimes:\n",
    "                label = crimesEncoding[tag]\n",
    "                labelTag = tag\n",
    "                break\n",
    "\n",
    "        if label != None:\n",
    "\n",
    "            rand = random.random()\n",
    "\n",
    "            if rand <= 0.6666:\n",
    "                crimesTextsTrain[labelTag] = crimesTextsTrain[labelTag] +\" \"+ text\n",
    "            \n",
    "            else:\n",
    "                crimesTextsTest[labelTag] = crimesTextsTrain[labelTag] +\" \"+ text\n",
    "                \n",
    "\n",
    "with open('trainStackeByTag.csv', mode='a') as employee_file:\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    for k, v in crimesTextsTrain.items():\n",
    "        employee_writer.writerow([label, text])\n",
    "        \n",
    "with open('testStackeByTag.csv', mode='a') as employee_file:\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    for k, v in crimesTextsTest.items():\n",
    "        employee_writer.writerow([label, text])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
